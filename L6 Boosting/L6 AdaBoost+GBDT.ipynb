{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L6 提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提升二分类训练器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对原始数据加权，并不断优化权重，对弱分类器进行提升得到强分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "强分类器是弱分类器的线性组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据 乳腺癌数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data.shape)\n",
    "print(cancer.feature_names)\n",
    "print(set(cancer.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.DataFrame(cancer.data,columns = cancer.feature_names)[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = cancer.target[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(cancer.data,columns = cancer.feature_names)[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = cancer.target[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需把y_data中的0替换为-1以便后续计算需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data[y_data==0] = -1.0\n",
    "y_test[y_test==0] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个树桩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data , feature , value , judge):\n",
    "    \n",
    "    #根据所给的特征和值对数据进行分类\n",
    "    \n",
    "    judgeArray = np.ones(data.shape[0])\n",
    "    \n",
    "    if judge == 'large':\n",
    "        #如果比value大，则分为0，即没有癌症\n",
    "        judgeArray[data[feature] > value] = -1.0\n",
    "    \n",
    "    else:\n",
    "        #如果比value小，则分为0，即没有癌症\n",
    "        judgeArray[data[feature] <= value] = -1.0\n",
    "        \n",
    "    \n",
    "    return judgeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stump(x_data , y_data , D):\n",
    "    \n",
    "    #建立一个单层决策树，返回：分类器、误差率、分类结果\n",
    "    \n",
    "    #D是权重向量\n",
    "    \n",
    "    #初始化变量\n",
    "    Stump = {}\n",
    "    minErr = np.inf\n",
    "    stepLen = 20\n",
    "    bestClass = np.ones(len(y_data))\n",
    "    \n",
    "    #树桩\n",
    "    for x_feature in x_data.columns:\n",
    "        rangeMin = x_data[x_feature].min()\n",
    "        rangeMax = x_data[x_feature].max()\n",
    "        steps = ( rangeMax - rangeMin ) / stepLen #对于连续变量进行分段取值\n",
    "        \n",
    "        for step in range(-1,int(stepLen)+1):\n",
    "            for judge in ['large', 'small']:\n",
    "                value = rangeMin + float(step) * steps\n",
    "                predictClass = split(x_data , x_feature , value , judge)\n",
    "                errArray = np.ones(len(y_data))\n",
    "                errArray[predictClass == y_data] = 0.0\n",
    "                err = np.dot(D , errArray)\n",
    "                \n",
    "                if err < minErr:\n",
    "                    minErr = err\n",
    "                    bestClass = predictClass.copy()\n",
    "                    \n",
    "                    Stump['feature'] = x_feature\n",
    "                    Stump['value'] = value\n",
    "                    Stump['judge'] = judge\n",
    "    \n",
    "    return Stump , minErr , bestClass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 , example2 , example3 = Stump(x_data , y_data , np.ones(len(y_data))/len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 'mean concave points', 'value': 0.0503, 'judge': 'large'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样建立了一个单层决策树：当特征'worst perimeter'的值大于110.6469时预测为0，即没有癌症"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoostDt(x_data , y_data , iterNum):\n",
    "    \n",
    "    #用adaboost提升单层决策树\n",
    "    \n",
    "    ClassTree = []\n",
    "    D = np.ones(len(y_data))/len(y_data)\n",
    "    weighBestClass = np.zeros(len(y_data))\n",
    "    i = 1\n",
    "    \n",
    "    while 1:\n",
    "        bestStump , error , bestClass = Stump(x_data , y_data , D)\n",
    "        α = 1/2 * np.log((1 - error) / (error + 1e-10))\n",
    "        bestStump['α'] = α\n",
    "        ClassTree.append(bestStump)\n",
    "        D = D * np.exp(-α * y_data * bestClass)\\\n",
    "            / np.sum(D * np.exp(-α * y_data * bestClass))\n",
    "        \n",
    "        #计算分类器的总误差\n",
    "        \n",
    "        weighBestClass += α * bestClass\n",
    "        grossErr = np.dot(np.sign(weighBestClass) != y_data ,\n",
    "                          np.ones(len(y_data))/len(y_data))\n",
    "        i += 1\n",
    "        if grossErr == 0.0:\n",
    "            break\n",
    "        \n",
    "        if i >= iterNum:\n",
    "            break\n",
    "    \n",
    "    return ClassTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AdaTree = AdaBoostDt(x_data , y_data , 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后用训练好的强分类器进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaForecast(x_test , AdaClassTree):\n",
    "    \n",
    "    #用分类器进行分类\n",
    "    \n",
    "    f = np.zeros(x_test.shape[0])\n",
    "    \n",
    "    for i in range(len(AdaClassTree)):\n",
    "        ClassOutPut = split(x_test , AdaClassTree[i]['feature'],\n",
    "                  AdaClassTree[i]['value'] , AdaClassTree[i]['judge'])\n",
    "        f += AdaClassTree[i]['α'] * ClassOutPut\n",
    "        G = np.sign(f)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = AdaForecast(x_test , AdaTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测误差率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028985507246376812"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(result1 != y_test , np.ones(len(y_test))/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2、梯度提升树（GBDT）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT基于单层的CART树进行提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据：波士顿房价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "{5.0, 6.3, 7.2, 8.8, 7.4, 10.2, 11.8, 12.7, 13.6, 14.5, 15.0, 16.5, 17.5, 18.9, 18.2, 20.4, 21.6, 22.9, 21.7, 24.0, 19.9, 26.6, 26.5, 27.5, 23.1, 27.1, 28.7, 24.7, 30.8, 33.4, 34.7, 34.9, 36.2, 35.4, 31.6, 33.0, 38.7, 33.2, 43.8, 41.3, 37.2, 39.8, 42.3, 48.5, 44.8, 50.0, 46.7, 48.3, 44.0, 48.8, 46.0, 10.5, 11.5, 11.0, 12.5, 12.0, 13.5, 13.0, 14.0, 16.6, 16.0, 16.1, 16.4, 17.4, 17.1, 17.0, 17.6, 17.9, 18.4, 18.6, 18.5, 18.0, 18.1, 19.6, 19.4, 19.5, 19.1, 19.0, 20.0, 20.5, 20.9, 20.6, 20.1, 21.0, 21.4, 21.5, 21.9, 21.1, 22.0, 22.5, 22.6, 22.4, 22.1, 23.4, 23.5, 23.9, 23.6, 23.0, 24.1, 24.6, 24.4, 24.5, 25.0, 25.1, 26.4, 27.0, 27.9, 28.0, 28.4, 28.1, 28.5, 28.6, 29.4, 29.9, 29.6, 29.1, 29.0, 30.5, 30.1, 31.1, 31.5, 31.0, 32.5, 32.0, 32.9, 32.4, 32.2, 33.3, 33.8, 33.1, 32.7, 8.4, 34.6, 35.2, 35.1, 10.4, 10.9, 7.0, 36.4, 36.0, 36.5, 36.1, 11.9, 37.9, 37.0, 37.6, 37.3, 13.9, 13.4, 14.4, 14.9, 15.4, 8.5, 41.7, 42.8, 43.1, 43.5, 45.4, 9.5, 8.3, 8.7, 9.7, 10.8, 11.3, 11.7, 12.3, 12.8, 13.2, 13.3, 13.8, 14.8, 14.3, 14.2, 15.2, 15.7, 15.3, 16.2, 16.8, 16.3, 16.7, 17.3, 17.8, 17.2, 17.7, 18.7, 18.8, 18.3, 19.3, 19.7, 19.8, 19.2, 20.2, 20.8, 20.3, 20.7, 21.2, 21.8, 22.2, 22.8, 22.7, 22.3, 23.3, 23.8, 23.2, 23.7, 24.8, 24.2, 24.3, 25.3, 25.2, 26.7, 26.2, 7.5, 28.2, 29.8, 30.3, 30.7, 5.6, 31.7, 31.2, 8.1, 9.6, 12.1, 12.6, 13.1, 14.6, 14.1, 15.6, 15.1}\n"
     ]
    }
   ],
   "source": [
    "print(boston.data.shape)\n",
    "print(boston.feature_names)\n",
    "print(set(boston.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同于上一个数据集，这里的房价是一个连续变量，需用回归树进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_boston = pd.DataFrame(boston.data,columns = boston.feature_names)[0:400]\n",
    "y_boston = pd.DataFrame(boston.target , columns = {'Y'})[0:400]\n",
    "x_boston_test = pd.DataFrame(boston.data,columns = boston.feature_names)[400:]\n",
    "y_boston_test = pd.DataFrame(boston.target , columns = {'Y'})[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = pd.merge(x_boston , y_boston , on = x_boston.index)\n",
    "boston_test = pd.merge(x_boston_test , y_boston_test , on = x_boston_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立一个单层的CART树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data , feature , value):\n",
    "    \n",
    "    #根据所给的特征和值分割数据集\n",
    "    \n",
    "    left_data = data[data[feature] > value].drop(feature , axis = 1)\n",
    "    right_data = data[data[feature] <= value].drop(feature , axis = 1)\n",
    "    \n",
    "    return left_data , right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr_error(data):\n",
    "    \n",
    "    #损失函数：平方误差\n",
    "    \n",
    "    return np.var(data.iloc[:,-1]) * len(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cut(data):\n",
    "    \n",
    "    #寻找最佳的分割特征和值\n",
    "    \n",
    "    best_S = np.inf\n",
    "    s = 0.0\n",
    "    bestFeature = None\n",
    "    bestValue = 0.0\n",
    "    \n",
    "    for x_feature in data.columns[:-1]:\n",
    "        for value in list(set(data[x_feature])):    \n",
    "            left_data , right_data = split(data , x_feature , value)\n",
    "\n",
    "            s = sqr_error(left_data) + sqr_error(right_data)\n",
    "            \n",
    "            if s < best_S:\n",
    "                bestFeature = x_feature\n",
    "                bestValue = value\n",
    "                best_S = s\n",
    "                \n",
    "    \n",
    "    return bestFeature , bestValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CART_Stump(data):\n",
    "    \n",
    "    #种树桩\n",
    "    \n",
    "    #如果所有特征都一样，停止分割\n",
    "    if len(set(data.iloc[:,-1])) == 1:\n",
    "        return flowers[data.iloc[:,-1].mode()[0]]\n",
    "    \n",
    "    \n",
    "    feature , value = best_cut(data)\n",
    "    \n",
    "    \n",
    "    cartStump = {}\n",
    "    left_tree , right_tree = split(data , feature , value)\n",
    "    y = data.columns[-1]\n",
    "    large = left_tree[y].mean()\n",
    "    small = right_tree[y].mean()\n",
    "    \n",
    "    cartStump['feature'] = feature\n",
    "    cartStump['value'] = value\n",
    "    cartStump['large'] = large\n",
    "    cartStump['small'] = small\n",
    "    \n",
    "\n",
    "    return cartStump , left_tree , right_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump , l , r = CART_Stump(boston_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossFunction(forcast , real):\n",
    "    \n",
    "    #定义损失函数\n",
    "    \n",
    "    L = np.sum((real - forcast) ** 2)\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
